{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_selection(train_x, train_y, M, seed):\n",
    "    new_train_x = []\n",
    "    new_train_y = []\n",
    "    for i in range(10):\n",
    "        sub_train_x = train_x[train_y==i]\n",
    "        kmeans = KMeans(n_clusters = M//10, random_state=seed).fit(sub_train_x)\n",
    "        new_train_x.extend(kmeans.cluster_centers_)\n",
    "        new_train_y.extend([i]*(M//10))\n",
    "    return new_train_x, new_train_y\n",
    "\n",
    "def load_embeddings(path='data'):\n",
    "    return np.load(os.path.join(path, \"train_x.npy\")), np.load(os.path.join(path, \"train_y.npy\")), np.load(os.path.join(path, \"test_x.npy\")), np.load(os.path.join(path, \"test_y.npy\"))\n",
    "\n",
    "def embedded_pipeline(M, select_func, t, Iteration, seeds=list(range(5)), path=\"./data\"):\n",
    "    train_X, train_Y, test_X, test_Y = load_embeddings(path)\n",
    "    accs = []\n",
    "    for iter, seed in zip(range(Iteration), seeds):\n",
    "        train_x, train_y, test_x, test_y = np.copy(train_X), np.copy(train_Y), np.copy(test_X), np.copy(test_Y)\n",
    "        train_x, train_y = select_func(train_x, train_y, M, seed)\n",
    "        classifier = KNeighborsClassifier(n_neighbors=1, algorithm=\"brute\")\n",
    "        classifier.fit(train_x, train_y)\n",
    "        classifier.score(test_x,test_y)\n",
    "        acc = classifier.score(test_x, test_y)\n",
    "        accs.append(acc)\n",
    "        print(f\"Iter: {iter}  Acc: {acc}\")\n",
    "        classifier = None\n",
    "    \n",
    "    accs = np.array(accs)\n",
    "    mean = accs.mean()\n",
    "    std = np.std(accs)\n",
    "    std_sample = np.std(accs, ddof=1)\n",
    "    interval = (mean-t*std_sample/np.sqrt(len(accs)),mean+t*std_sample/np.sqrt(len(accs)))\n",
    "    \n",
    "    return accs, mean, std, std_sample, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = timm.create_model(\"resnet18\", pretrained=False, num_classes=10)\n",
    "resnet.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "resnet.load_state_dict(\n",
    "  torch.hub.load_state_dict_from_url(\n",
    "    \"https://huggingface.co/gpcarl123/resnet18_mnist/resolve/main/resnet18_mnist.pth\",\n",
    "    map_location=\"cpu\",\n",
    "    file_name=\"resnet18_mnist.pth\",\n",
    "  )\n",
    ")\n",
    "resnet.fc=nn.Identity()\n",
    "preprocessor = torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=64, shuffle=False)\n",
    "testloader = DataLoader(dataset=trainset, batch_size=64, shuffle=False)\n",
    "\n",
    "resnet = resnet.to(\"cuda\")\n",
    "\n",
    "new_x = []\n",
    "new_y = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(trainloader):\n",
    "        x = x.to(\"cuda\")\n",
    "        x = resnet(preprocessor(x))\n",
    "        x = x.cpu().numpy()\n",
    "        new_x.extend(x)\n",
    "        new_y.extend(y)\n",
    "    \n",
    "new_x = np.array(new_x)\n",
    "np.save(\"data/train_x\", new_x)\n",
    "new_y = np.array(new_y)\n",
    "np.save(\"data/train_y\", new_y)\n",
    "\n",
    "new_x = []\n",
    "new_y = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(testloader):\n",
    "        x = x.to(\"cuda\")\n",
    "        x = resnet(x)\n",
    "        x = x.cpu().numpy()\n",
    "        new_x.extend(x)\n",
    "        new_y.extend(y)\n",
    "    \n",
    "new_x = np.array(new_x)\n",
    "np.save(\"data/test_x\", new_x)\n",
    "new_y = np.array(new_y)\n",
    "np.save(\"data/test_y\", new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = [10, 100, 1000, 5000, 10000]\n",
    "\n",
    "for M in Ms:\n",
    "    print(f\"M: {M}\")\n",
    "    accs, mean, std, std_sample, interval = embedded_pipeline(M, select_func=kmean_selection, t=t095, Iteration=Iteration, seeds=[17, 26, 58, 96, 42])\n",
    "\n",
    "    print(f\"Accuracies: {accs}\")  \n",
    "    print(\"Mean: {:.5f}\".format(mean))\n",
    "    print(\"Standard Deviation: {:.5}\".format(std))\n",
    "    print(\"Confidence Interval: ({:.5f}  {:.5f})\".format(interval[0], interval[1]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
